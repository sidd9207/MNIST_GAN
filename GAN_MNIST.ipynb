{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25039114-e059-4dbe-95b8-9bf96a004308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "971fd493-916a-4906-869d-82258a2df507",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_dim):\n",
    "        super().__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Linear(img_dim, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.disc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31efa1fb-f4d5-4219-ae8f-b043dcc8026a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, img_dim):\n",
    "        super().__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(z_dim, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256, img_dim),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.gen(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d54973cc-30f0-4e97-afeb-0aa6b7aecb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "lr = 3e-4\n",
    "z_dim = 64\n",
    "image_dim = 784\n",
    "batch_size = 32\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36163f99-7a6a-4577-a50f-2d750fc60315",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = Discriminator(image_dim).to(device)\n",
    "gen = Generator(z_dim, image_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d935fe4f-6bcd-4770-aa5d-2ce377ca0750",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_noise = torch.randn(batch_size, z_dim).to(device)\n",
    "transforms = torchvision.transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.5,], [0.5,])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35c22998-e059-4e0d-969a-5e43945155d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.MNIST(root=\"dataset/\", transform=transforms, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40b1a388-d79e-4446-9335-c025b58bd104",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a18720ce-4d22-4649-9193-20af2ea9f82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_disc = optim.Adam(disc.parameters(), lr=lr)\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de641c13-6113-4b11-99ed-9ef488648b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d56f20a-84db-4bbb-9d42-3c3a5df0de05",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_fake = SummaryWriter(f\"runs/GAN_MNIST/fake\")\n",
    "writer_real = SummaryWriter(f\"runs/GAN_MNIST/real\")\n",
    "step=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "183677a2-8097-46af-88b4-6579f3b55414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/50] \\ Loss D: 0.6594, Loss G: 0.6849\n",
      "Epoch [1/50] \\ Loss D: 0.3873, Loss G: 1.3702\n",
      "Epoch [2/50] \\ Loss D: 0.3988, Loss G: 1.4343\n",
      "Epoch [3/50] \\ Loss D: 0.5193, Loss G: 1.2034\n",
      "Epoch [4/50] \\ Loss D: 0.7504, Loss G: 0.8864\n",
      "Epoch [5/50] \\ Loss D: 0.5536, Loss G: 1.1914\n",
      "Epoch [6/50] \\ Loss D: 0.8659, Loss G: 0.6394\n",
      "Epoch [7/50] \\ Loss D: 0.4684, Loss G: 1.4066\n",
      "Epoch [8/50] \\ Loss D: 0.5996, Loss G: 1.1461\n",
      "Epoch [9/50] \\ Loss D: 0.6581, Loss G: 1.1523\n",
      "Epoch [10/50] \\ Loss D: 0.5981, Loss G: 1.1019\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m----> 2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreal\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:277\u001b[0m, in \u001b[0;36mNormalize.forward\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    270\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;124;03m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\transforms\\functional.py:363\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg should be Tensor Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\transforms\\_functional_tensor.py:922\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    920\u001b[0m mean \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(mean, dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    921\u001b[0m std \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(std, dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m--> 922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m(\u001b[49m\u001b[43mstd\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43many\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    923\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstd evaluated to zero after conversion to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, leading to division by zero.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mean\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (real, _) in enumerate(loader):\n",
    "        real = real.view(real.shape[0], -1).to(device)\n",
    "        batch_size = real.shape[0]\n",
    "\n",
    "        #Train Discriminator\n",
    "        opt_disc.zero_grad()\n",
    "        \n",
    "        noise = torch.randn(batch_size, z_dim).to(device)\n",
    "        fake = gen(noise)\n",
    "        disc_real = disc(real)\n",
    "        loss_D_real = criterion(disc_real, torch.ones(disc_real.shape[0], 1).to(device))\n",
    "        disc_fake = disc(fake)\n",
    "        loss_D_fake = criterion(disc_fake, torch.zeros(disc_real.shape[0], 1).to(device))\n",
    "        loss_D_total = (loss_D_real + loss_D_fake) / 2\n",
    "        loss_D_total.backward(retain_graph=True)\n",
    "        opt_disc.step()\n",
    "\n",
    "\n",
    "        #Train Generator\n",
    "        opt_gen.zero_grad()\n",
    "        \n",
    "        output = disc(fake)\n",
    "        loss_G = criterion(output, torch.ones(output.shape[0], 1).to(device))\n",
    "        loss_G.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        #Tensorboard stuff\n",
    "        if batch_idx == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{num_epochs}] \\ \"\n",
    "                f\"Loss D: {loss_D_total:.4f}, Loss G: {loss_G:.4f}\"\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fake = gen(noise).view(-1, 1, 28, 28)\n",
    "                data = real.view(-1, 1, 28, 28)\n",
    "                img_grid_fake = torchvision.utils.make_grid(fake, normalize=True)\n",
    "                img_grid_real = torchvision.utils.make_grid(data, normalize=True)\n",
    "\n",
    "                writer_fake.add_image(\n",
    "                    \"Generated Images\", img_grid_fake, global_step=step\n",
    "                )\n",
    "                writer_real.add_image(\n",
    "                    \"Real Images\", img_grid_real, global_step=step\n",
    "                )\n",
    "                step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d31039a-d0ed-486d-8a60-5e03e5681155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c329fc17-77fa-451c-97df-75c7e95949d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd5327b4-ba2f-46a5-b27c-31b6b9fd37d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-cff164f72b3a2698\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-cff164f72b3a2698\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=runs  --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88dfa831-90ff-4605-b7c1-d1ef7c51ace9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gen, \"MNIST_generator.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26e5874d-ee62-4bb1-9bfa-cddfa0956998",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(disc, \"MNIST_discriminator.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7f33ef94-ad99-4640-985b-c988dbc6d3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1dd6b5c4-7e10-41ab-8dee-bf1e8b6c992c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8032d775-306f-4155-a9c4-c691e79e0e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "303fc5b8-baa9-4a2e-b7ae-575b59fdd55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b183c6c850>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAf0UlEQVR4nO3df2xV9f3H8ddtaS+/2oul0B9SsOAPnPyKTCoRmY4OqIsBxc1fS2AxGrC4IXOaEhXdlnRjmxoXplm2gE5RNBGYqBgEKUMBB8IIUzva1bUILYr2XlqglN7z/YPY765Q4HO4t+/b8nwkJ6H3nlfvm9PTvnp6bz8NeJ7nCQCATpZiPQAA4PxEAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMBED+sBvikajWrfvn3KyMhQIBCwHgcA4MjzPB06dEj5+flKSen4OifpCmjfvn0qKCiwHgMAcI7q6uo0aNCgDu9Puh/BZWRkWI8AAIiDM309T1gBLV68WBdddJF69uypoqIiffDBB2eV48duAJA4gUDAeTuXxzqdhBTQ8uXLNX/+fC1cuFAffvihRo8erSlTpujAgQOJeDgAQFfkJcC4ceO80tLS9rfb2tq8/Px8r7y8/IzZcDjsSWJjY2NjS8AWCAScN7+PFQ6HT/v1Pu5XQMeOHdP27dtVXFzcfltKSoqKi4u1efPmk/ZvaWlRJBKJ2QAA3V/cC+iLL75QW1ubcnJyYm7PyclRfX39SfuXl5crFAq1b7wCDgDOD+avgisrK1M4HG7f6urqrEcCAHSCuP8eUHZ2tlJTU9XQ0BBze0NDg3Jzc0/aPxgMKhgMxnsMAECSi/sVUHp6usaOHat169a13xaNRrVu3TqNHz8+3g8HAOiiErISwvz58zVz5kx9+9vf1rhx4/TUU0+publZP/7xjxPxcACALighBXTrrbfq888/16OPPqr6+nqNGTNGa9asOemFCQCA81fA8zzPeoj/FYlEFAqFOuWxevbs6St39OjROE8CAN1POBxWZmZmh/ebvwoOAHB+ooAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYCIhq2F3FSwq2n0FAgFfuSRbm7dLSUlx/342Go06Zy6++GLnTFVVlXNG8ncecQ6dPa6AAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmzuvVsNF9sSLxuenRw/1Lw/Hjx50zAwYMcM74XdkayYcrIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACZYjBTdUiAQ8JXzs4hpWlqacyYYDDpnmpubO+VxJH/H7/e//71z5umnn3bOfPnll86ZPn36OGckqampyTnDQrhnjysgAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJliMNIn5WRAy2RdCTE1Ndc5Eo9EETHJqfuZrbW11zhw/ftw5M3LkSOfM/v37nTOS9Pe//90588YbbzhnevXq5Zz57LPPnDNjxoxxzkhSSor79+iNjY2+Hut8xBUQAMAEBQQAMBH3AnrssccUCARituHDh8f7YQAAXVxCngO64oor9M477/z/g/TgqSYAQKyENEOPHj2Um5ubiHcNAOgmEvIc0J49e5Sfn6+hQ4fqzjvvVG1tbYf7trS0KBKJxGwAgO4v7gVUVFSkpUuXas2aNXrmmWdUU1Oja6+9VocOHTrl/uXl5QqFQu1bQUFBvEcCACShuBdQSUmJfvCDH2jUqFGaMmWK3nzzTTU2NuqVV1455f5lZWUKh8PtW11dXbxHAgAkoYS/OqBfv3669NJLVVVVdcr7g8GggsFgoscAACSZhP8eUFNTk6qrq5WXl5fohwIAdCFxL6AHHnhAFRUV+vTTT/X+++/rpptuUmpqqm6//fZ4PxQAoAuL+4/g9u7dq9tvv10HDx7UgAEDNGHCBG3ZskUDBgyI90MBALqwgJdkq1dGIhGFQiHrMU6rsxYJzczMdM50x5ex+zkfOnrV5ZnccMMNzpk1a9Y4Z3Jycpwzfo5DUVGRc0aSZs+e7Zx54oknnDOjR492znz11VfOmW3btjlnJGnatGnOmbKyMufMkSNHnDN+Fs6VpLa2Nl85P8Lh8Gm/jrEWHADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMJ/4N03VFnrd/qZ2HRlJTO+54iGo06Z/ws5Nrc3Oyc8TObJL399tvOmaFDh/p6LFfPPfecc8bv4rS9evVyzgwcONA5M2HCBOfM/PnznTMff/yxc0aS3n33XedMZ30O+l1UtLMWUz4bXAEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAEx0m9Ww+/bt65xpampKwCS2/K4C3Vn8rKp7/Phx50wwGHTOSFJLS4tz5rPPPnPO/OlPf3LOjBw50jmzadMm54wk/fWvf3XO/PnPf3bO7N271znTo4f7ly0/K6pLUnp6unPm2LFjvh6rs3TWav5ngysgAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJrrNYqTJvrBoIBBwziTTooFdjZ9FRSUpFAo5Z/r37++cyc7Ods74WeRywYIFzhlJamxsdM6kpqY6Z95++23njN+PrR9paWnOGT8fp5QU92uBZF94+GxwBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMBEt1mMNNmxsGjnysrK8pU7fPiwc2b8+PHOmeuvv94506OH+6frLbfc4pyRpGeffdY509zc7JxJT093zvg5Dm1tbc4Zyd//yY/usLCoH1wBAQBMUEAAABPOBbRx40bdeOONys/PVyAQ0MqVK2Pu9zxPjz76qPLy8tSrVy8VFxdrz5498ZoXANBNOBdQc3OzRo8ercWLF5/y/kWLFunpp5/Ws88+q61bt6pPnz6aMmWKjh49es7DAgC6D+dn80pKSlRSUnLK+zzP01NPPaWHH35Y06ZNkyQ9//zzysnJ0cqVK3Xbbbed27QAgG4jrs8B1dTUqL6+XsXFxe23hUIhFRUVafPmzafMtLS0KBKJxGwAgO4vrgVUX18vScrJyYm5PScnp/2+byovL1coFGrfCgoK4jkSACBJmb8KrqysTOFwuH2rq6uzHgkA0AniWkC5ubmSpIaGhpjbGxoa2u/7pmAwqMzMzJgNAND9xbWACgsLlZubq3Xr1rXfFolEtHXrVl+/LQ4A6L6cXwXX1NSkqqqq9rdramq0c+dOZWVlafDgwZo3b55+9atf6ZJLLlFhYaEeeeQR5efna/r06fGcGwDQxTkX0LZt22LWsZo/f74kaebMmVq6dKkefPBBNTc365577lFjY6MmTJigNWvWqGfPnvGbGgDQ5QW8JFslMxKJKBQKWY+BLs7PIpeSdPDgQedMnz59nDOfffaZcyY1NdU54/fTu6Pf9Tud3bt3O2dWr17tnLnhhhucM7ARDodP+7y++avgAADnJwoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACec/x9CdpKWl+cq1trbGeRLEW21tra9c3759nTPRaNQ5M2jQIOeMn5Wt//Of/zhnJH/H4Xvf+55zprCw0DmTl5fnnPnmX2k+W34+tp0lGAz6yrW0tMR5Ev+4AgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGAi4PlZ4TCBIpGIQqGQ9RinlZLi3tv/+te/nDOXX365cybZBQIB58wLL7zgnLnjjjucM8nu0KFDzpn09HRfj/WPf/zDOXP77bc7Z/wsqOlnYdGmpibnDM5dOBxWZmZmh/dzBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMBE0i5G2q9fP6eFK7/66qsEToV46dGjh3OmpqbGOXPhhRc6ZyTJz6fDJ5984pz5/ve/75x5//33nTMbN250zkjStGnTnDN+jt0vf/lL58zy5cudM3v37nXOSNKxY8d85XACi5ECAJISBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAE0m7GCmSX58+fTol07t3b+dMJBJxzkhSfn6+c8bPYqQpKe7f+0WjUefMmDFjnDOS9N577zln/v3vfztn/va3vzlnamtrnTPNzc3OGUl64YUXfOVwAouRAgCSEgUEADDhXEAbN27UjTfeqPz8fAUCAa1cuTLm/lmzZikQCMRsU6dOjde8AIBuwrmAmpubNXr0aC1evLjDfaZOnar9+/e3by+99NI5DQkA6H6c/zxlSUmJSkpKTrtPMBhUbm6u76EAAN1fQp4D2rBhgwYOHKjLLrtMc+bM0cGDBzvct6WlRZFIJGYDAHR/cS+gqVOn6vnnn9e6dev0m9/8RhUVFSopKVFbW9sp9y8vL1coFGrfCgoK4j0SACAJOf8I7kxuu+229n+PHDlSo0aN0rBhw7RhwwZNmjTppP3Lyso0f/789rcjkQglBADngYS/DHvo0KHKzs5WVVXVKe8PBoPKzMyM2QAA3V/CC2jv3r06ePCg8vLyEv1QAIAuxPlHcE1NTTFXMzU1Ndq5c6eysrKUlZWlxx9/XDNmzFBubq6qq6v14IMP6uKLL9aUKVPiOjgAoGtzLqBt27bp+uuvb3/76+dvZs6cqWeeeUa7du3Sc889p8bGRuXn52vy5Mn65S9/qWAwGL+pAQBdHouRdpJAIOCc6awPjZ/ZJGnYsGHOmcbGRufMl19+6Zzx+3/q6NWaXVVWVpav3JVXXumcefLJJ50zfhYJ9bNgbGFhoXNGSu7zwe85npaW5pw5duyYr8diMVIAQFKigAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiI+5/kxqn5XbnWlZ8VtP3Otnfv3k7JDBgwwDmTksL3VpK/lcQl6ciRI86ZaDTqnMnJyXHO9O/f3znTs2dP54xfflb49sPvavl+V7ZOBD5LAQAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmGAx0k7iZ6HGrKws50xVVZVzZvHixc4ZSZowYYJz5s0333TOFBUVOWdqamqcM5J04MAB54zfRSFd+Vlg1c95J0kLFixwzkQiEeeMn4Vws7OznTNPPvmkc0aS7r33XudMjx7uX1b9HIfW1lbnTLLhCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAICJgNdZKymepUgkolAopOzsbKfFF/0sIulXTk6Oc8bPfLfccotz5vPPP3fOvPHGG84ZSfr000+dM9/61recM0ePHnXO/POf/3TOSNLs2bOdM9XV1c6ZpqYm50xnfqr27NnTOTN06FDnzODBg50zjzzyiHNm7dq1zhlJ2rp1q3Pmrbfecs74WXDXz2ydLRwOKzMzs8P7uQICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgImkXI+1u8vLynDO1tbXOmS+//NI507t3b+eMJPXp08c5EwgEnDNffPGFc8bvaX399dc7Zz766CPnTJJ92p0kNTXVOePn/7R8+XLnzA9/+EPnjN/j7ed8TfaPbWdiMVIAQFKigAAAJpwKqLy8XFdddZUyMjI0cOBATZ8+XZWVlTH7HD16VKWlperfv7/69u2rGTNmqKGhIa5DAwC6PqcCqqioUGlpqbZs2aK1a9eqtbVVkydPVnNzc/s+999/v15//XW9+uqrqqio0L59+3TzzTfHfXAAQNfWw2XnNWvWxLy9dOlSDRw4UNu3b9fEiRMVDof1l7/8RcuWLdN3v/tdSdKSJUt0+eWXa8uWLbr66qvjNzkAoEs7p+eAwuGwJCkrK0uStH37drW2tqq4uLh9n+HDh2vw4MHavHnzKd9HS0uLIpFIzAYA6P58F1A0GtW8efN0zTXXaMSIEZKk+vp6paenq1+/fjH75uTkqL6+/pTvp7y8XKFQqH0rKCjwOxIAoAvxXUClpaXavXu3Xn755XMaoKysTOFwuH2rq6s7p/cHAOganJ4D+trcuXO1evVqbdy4UYMGDWq/PTc3V8eOHVNjY2PMVVBDQ4Nyc3NP+b6CwaCCwaCfMQAAXZjTFZDneZo7d65WrFih9evXq7CwMOb+sWPHKi0tTevWrWu/rbKyUrW1tRo/fnx8JgYAdAtOV0ClpaVatmyZVq1apYyMjPbndUKhkHr16qVQKKS77rpL8+fPV1ZWljIzM3Xfffdp/PjxvAIOABDDqYCeeeYZSdJ1110Xc/uSJUs0a9YsSdKTTz6plJQUzZgxQy0tLZoyZYr++Mc/xmVYAED3wWKkPvh5zsrPooabNm1yztxyyy3Oma+/sXDlZ+HO9PR058zWrVudMzt27HDOSNK9997rK9fdpKS4vz7Jz5cSP4/T1tbmnBk3bpxzRpI++OADX7nOkJaW5ivX2toa50k6xmKkAICkRAEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwwWrYnaRHD/c/PnvBBRc4Z9555x3nzO9+9zvnjCRff2bjJz/5iXNm+PDhzpkFCxY4ZyR/Ky2jc6Wmpjpn/H5c+/bt65xpamry9VjdEathAwCSEgUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMsRprE/CxgOmLECOeM38UTx4wZ45y58sornTN+FhYNBALOGUlKsk8HoEtjMVIAQFKigAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABg4rxejDQ1NdVXrq2tLc6T2Bo2bJiv3L59+5wzR44c8fVYSH5+FoD1k4lGo86Z7igYDPrKtbS0xHmSjrEYKQAgKVFAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADDRw3qAeElJce/S7raoqORvccfq6uoETILzTc+ePZ0zLE7rX2cuKpooXAEBAExQQAAAE04FVF5erquuukoZGRkaOHCgpk+frsrKyph9rrvuOgUCgZht9uzZcR0aAND1ORVQRUWFSktLtWXLFq1du1atra2aPHmympubY/a7++67tX///vZt0aJFcR0aAND1Ob0IYc2aNTFvL126VAMHDtT27ds1ceLE9tt79+6t3Nzc+EwIAOiWzuk5oHA4LEnKysqKuf3FF19Udna2RowYobKyMh0+fLjD99HS0qJIJBKzAQC6P98vw45Go5o3b56uueYajRgxov32O+64Q0OGDFF+fr527dqlhx56SJWVlXrttddO+X7Ky8v1+OOP+x0DANBFBTzP8/wE58yZo7feekubNm3SoEGDOtxv/fr1mjRpkqqqqjRs2LCT7m9paYl5PXskElFBQYHzPH5+DygajTpnkp2f3wPyeQoAMXr16uWc4feAurdwOKzMzMwO7/d1BTR37lytXr1aGzduPG35SFJRUZEkdVhAwWBQwWDQzxgAgC7MqYA8z9N9992nFStWaMOGDSosLDxjZufOnZKkvLw8XwMCALonpwIqLS3VsmXLtGrVKmVkZKi+vl6SFAqF1KtXL1VXV2vZsmW64YYb1L9/f+3atUv333+/Jk6cqFGjRiXkPwAA6JqcngPq6PmFJUuWaNasWaqrq9OPfvQj7d69W83NzSooKNBNN92khx9++LQ/B/xfkUhEoVDobEdqx3NAJ/AcEKzwHBC+6UzPAfl+EUKiUEDnhgKCFQoI35SQFyF0hlAo5PTFtLGxMXHDdCGUCaxQJnDFYqQAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMJO1ipOFw2HoEnIcee+yxTsmgc1199dW+clu2bInzJPhfXAEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwETSrQXneZ71CDiPHT161HoEJMDx48etRzgvnenrecBLsq/4e/fuVUFBgfUYAIBzVFdXp0GDBnV4f9IVUDQa1b59+5SRkaFAIBBzXyQSUUFBgerq6pSZmWk0oT2OwwkchxM4DidwHE5IhuPgeZ4OHTqk/Px8paR0/ExP0v0ILiUl5bSNKUmZmZnn9Qn2NY7DCRyHEzgOJ3AcTrA+DqFQ6Iz78CIEAIAJCggAYKJLFVAwGNTChQsVDAatRzHFcTiB43ACx+EEjsMJXek4JN2LEAAA54cudQUEAOg+KCAAgAkKCABgggICAJjoMgW0ePFiXXTRRerZs6eKior0wQcfWI/U6R577DEFAoGYbfjw4dZjJdzGjRt14403Kj8/X4FAQCtXroy53/M8Pfroo8rLy1OvXr1UXFysPXv22AybQGc6DrNmzTrp/Jg6darNsAlSXl6uq666ShkZGRo4cKCmT5+uysrKmH2OHj2q0tJS9e/fX3379tWMGTPU0NBgNHFinM1xuO666046H2bPnm008al1iQJavny55s+fr4ULF+rDDz/U6NGjNWXKFB04cMB6tE53xRVXaP/+/e3bpk2brEdKuObmZo0ePVqLFy8+5f2LFi3S008/rWeffVZbt25Vnz59NGXKlG63sOiZjoMkTZ06Neb8eOmllzpxwsSrqKhQaWmptmzZorVr16q1tVWTJ09Wc3Nz+z7333+/Xn/9db366quqqKjQvn37dPPNNxtOHX9ncxwk6e677445HxYtWmQ0cQe8LmDcuHFeaWlp+9ttbW1efn6+V15ebjhV51u4cKE3evRo6zFMSfJWrFjR/nY0GvVyc3O93/72t+23NTY2esFg0HvppZcMJuwc3zwOnud5M2fO9KZNm2Yyj5UDBw54kryKigrP80587NPS0rxXX321fZ+PP/7Yk+Rt3rzZasyE++Zx8DzP+853vuP99Kc/tRvqLCT9FdCxY8e0fft2FRcXt9+WkpKi4uJibd682XAyG3v27FF+fr6GDh2qO++8U7W1tdYjmaqpqVF9fX3M+REKhVRUVHRenh8bNmzQwIEDddlll2nOnDk6ePCg9UgJFQ6HJUlZWVmSpO3bt6u1tTXmfBg+fLgGDx7crc+Hbx6Hr7344ovKzs7WiBEjVFZWpsOHD1uM16GkW4z0m7744gu1tbUpJycn5vacnBx98sknRlPZKCoq0tKlS3XZZZdp//79evzxx3Xttddq9+7dysjIsB7PRH19vSSd8vz4+r7zxdSpU3XzzTersLBQ1dXVWrBggUpKSrR582alpqZajxd30WhU8+bN0zXXXKMRI0ZIOnE+pKenq1+/fjH7dufz4VTHQZLuuOMODRkyRPn5+dq1a5ceeughVVZW6rXXXjOcNlbSFxD+X0lJSfu/R40apaKiIg0ZMkSvvPKK7rrrLsPJkAxuu+229n+PHDlSo0aN0rBhw7RhwwZNmjTJcLLEKC0t1e7du8+L50FPp6PjcM8997T/e+TIkcrLy9OkSZNUXV2tYcOGdfaYp5T0P4LLzs5WamrqSa9iaWhoUG5urtFUyaFfv3669NJLVVVVZT2Kma/PAc6Pkw0dOlTZ2dnd8vyYO3euVq9erXfffTfmz7fk5ubq2LFjamxsjNm/u54PHR2HUykqKpKkpDofkr6A0tPTNXbsWK1bt679tmg0qnXr1mn8+PGGk9lrampSdXW18vLyrEcxU1hYqNzc3JjzIxKJaOvWref9+bF3714dPHiwW50fnudp7ty5WrFihdavX6/CwsKY+8eOHau0tLSY86GyslK1tbXd6nw403E4lZ07d0pScp0P1q+COBsvv/yyFwwGvaVLl3offfSRd88993j9+vXz6uvrrUfrVD/72c+8DRs2eDU1Nd57773nFRcXe9nZ2d6BAwesR0uoQ4cOeTt27PB27NjhSfKeeOIJb8eOHd5///tfz/M879e//rXXr18/b9WqVd6uXbu8adOmeYWFhd6RI0eMJ4+v0x2HQ4cOeQ888IC3efNmr6amxnvnnXe8K6+80rvkkku8o0ePWo8eN3PmzPFCoZC3YcMGb//+/e3b4cOH2/eZPXu2N3jwYG/9+vXetm3bvPHjx3vjx483nDr+znQcqqqqvF/84hfetm3bvJqaGm/VqlXe0KFDvYkTJxpPHqtLFJDned4f/vAHb/DgwV56ero3btw4b8uWLdYjdbpbb73Vy8vL89LT070LL7zQu/XWW72qqirrsRLu3Xff9SSdtM2cOdPzvBMvxX7kkUe8nJwcLxgMepMmTfIqKytth06A0x2Hw4cPe5MnT/YGDBjgpaWleUOGDPHuvvvubvdN2qn+/5K8JUuWtO9z5MgR79577/UuuOACr3fv3t5NN93k7d+/327oBDjTcaitrfUmTpzoZWVlecFg0Lv44ou9n//85144HLYd/Bv4cwwAABNJ/xwQAKB7ooAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYOL/AO2/n1WuJcCeAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_noise = torch.randn(z_dim).to(device)\n",
    "gen_output = gen(val_noise)\n",
    "gen_output = gen_output.view(28, 28).to('cpu')\n",
    "plt.imshow(gen_output.detach().numpy(), cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
